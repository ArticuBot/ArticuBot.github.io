<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>ArticuBot</title>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="./static/css/academicons.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
</head>

<body>


    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">


                        <h1 class="title is-1 publication-title">
                         ArticuBot: Learning Universal Articulated Object Manipulation Policy via Large Scale Simulation
                        </h1>
                        <h3 class="title is-4 conference-authors"><a target="_blank" href="https://roboticsconference.org/">Robotics: Science and Systems (RSS) 2025</a>
                    </h3>
                        <div class="is-size-5 publication-authors">
                            <span class="author-block">
                                <a target="_blank" href="https://yufeiwang63.github.io/">
                                    Yufei Wang</a><sup>*,1</sup>,

                                <a target="_blank" href="https://articubot.github.io"> Ziyu Wang</a><sup>*2</sup>,

                                <a target="_blank" href="https://articubot.github.io"> Mino Nakura</a><sup>&dagger;1</sup>,
                                <a target="_blank"
                                    href="https://articubot.github.io">Pratik Bhowal</a><sup>&dagger;1</sup>,
                                <a target="_blank"
                                    href="https://sites.google.com/view/chialiangkuo">Chia-Liang Kuo</a><sup>&dagger;3</sup>,
                                <br>
                                <a target="_blank"
                                    href="https://sites.google.com/site/yitingchen0524/home">Yi-Ting Chen</a><sup>3</sup>,
                                <a target="_blank"
                                    href="https://zackory.com/">Zackory Erickson</a><sup>&Dagger;1</sup>,
                                <a target="_blank"
                                    href="http://davheld.github.io/">David Held</a><sup>&Dagger;1</sup>,

                            </span>
                        </div>

                        <div class="is-size-5 publication-authors">
                            <span class="author-block"><sup>1</sup>Robotics Institute, Carnegie Mellon University</span>
                            <span class="author-block"><sup>2</sup>IIIS, Tsinghua University </span>
                            <span class="author-block"><sup>3</sup>Department of Computer Science, National Yang Ming Chiao Tung University</span>
                        </div>
                        <div class="is-size-5 publication-authors">
                            <span class="author-block"><sup>&dagger;*</sup>Equal Contribution, <sup>&Dagger;</sup>Equal Advising </span>
                        </div>

                        <!-- <div class="is-size-5 column has-text-centered">
                          Robotics: Science and Systems (RSS) 2025
                        </div> -->

                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <!-- TODO REPLACE ALL LINKS -->
                                <span class="link-block">
                                    <a target="_blank" href="https://arxiv.org/abs/2503.03045"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="ai ai-arxiv"></i>
                                        </span>
                                        <span>arXiv</span>
                                    </a>
                                </span>

                                <span class="link-block">
                                    <a target="_blank" href="https://github.com/yufeiwang63/ArticuBot"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-github"></i>
                                        </span>
                                        <span>Code</span>
                                    </a>
                                </span>
                            </div>

                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="section" style="padding: 0">
        <div class="container is-max-desktop">
            <!-- Abstract. -->
            <div class="columns is-centered has-text-centered">
                <video poster="" id="" autoplay controls loop width="100%" playbackRate=2.0 style="border-radius: 5px;">
                    <source src="assets/website-demo-no-voice.mp4" type="video/mp4">
                </video>
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container is-max-desktop">
            <!-- Abstract. -->
            <div class="columns is-centered has-text-centered">
                <div class="column">
                    <h2 class="title is-3">Abstract</h2>
                    <div class="content has-text-justified">
                        <p style="font-size: 125%">
                          This paper presents ArticuBot, in which a single learned policy enables a robotics system to open diverse categories of unseen articulated objects in the real world.  This task has long been challenging for robotics due to the large variations in the geometry, size, and articulation types of such objects. 
                          Our system, ArticuBot, consists of three parts: generating a large number of demonstrations in physics-based simulation, distilling all generated demonstrations into a point cloud-based neural policy via imitation learning, and performing zero-shot sim2real transfer to real robotics systems.
                          Utilizing sampling-based grasping and motion planning, our demonstration generalization pipeline is fast and effective, generating a total of 42.3k demonstrations over 322 training articulated objects.
                          For policy learning, we propose a novel hierarchical policy representation, in which the high-level policy learns the sub-goal for the end-effector, and the low-level policy learns how to move the end-effector conditioned on the predicted goal.  We demonstrate that this hierarchical approach achieves much better object-level generalization compared to the non-hierarchical version. 
                          We further propose a novel weighted displacement model for the high-level policy that grounds the prediction into the existing 3D structure of the scene, outperforming alternative policy representations. 
                          We show that our learned policy can zero-shot transfer to three different real robot settings: a fixed table-top Franka arm across two different labs, and an X-Arm on a mobile base, opening multiple unseen articulated objects across two labs, real lounges, and kitchens.   
<br>
<br>
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>

      <section class="section" style="padding: 0">
        
        <div class="container is-max-desktop">
          <div class="column is-centered has-text-centered">
            <h2 class="title is-3">RSS Presentation Video</h2>
          </div>
          <br>
          <div class="columns is-centered has-text-centered">
                <video poster="" id="" autoplay controls loop width="100%" playbackRate=2.0 style="border-radius: 5px;">
                    <source src="assets/rss-presentation-v5.mp4" type="video/mp4">
                </video>
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container is-max-widescreen">
            <div class="rows">
                <div class="rows is-centered">
                    <div class="row is-full-width">
                        <h2 class="title is-3"><span class="dvima">ArticuBot System Overview</span></h2>
                        <!-- <img src="assets/pipeline.m4v" class="interpolation-image" alt=""
                            style="display: block; margin-left: auto; margin-right: auto; max-width: 80%;" /> -->
                            <video autoplay controls muted loop playsinline height="100%">
                              <source src="assets/overview.mp4"
                                      type="video/mp4">
                            </video>
                        <br>

                        <p style="font-size: 125%">
                          <span style="font-weight: bold">Top</span>: Overview of ArticuBot. We combine sampling-based grasping, motion planning, and opening actions to efficiently generate thousands of demonstrations in simulation. These demonstrations are distilled into a hierarchical policy via imitation learning, and then zero-shot transferred to real world.
                        <br>
                        <span style="font-weight: bold">Middle</span>: We propose a weighted displacement model for the high-level policy, which predicts the sub-goal end-effector pose. The weighted displacement model predicts the displacement from each point in the point cloud observation to the sub-goal end-effector, as well as a weight for each point. The final prediction is the weighted average of each point's prediction.  
                        <br>
                        <span style="font-weight: bold">Bottom</span>: We propose a goal-conditioned 3D diffusion policy for the low-level policy, which first applies attention between the current end-effector points, the scene points, and the goal end-effector points to obtain a latent embedding, and then performs diffusion on the latent embedding to generate the action, which is the delta transformation of the robot end-effector.
                        </p>
                        </div>
                </div>
            </div>
        </div>
    </section>

    <!-- <section class="section">
        <div class="container is-max-widescreen">
            <div class="rows">
                <div class="rows is-centered ">
                    <div class="row is-full-width">
                        <h2 class="title is-3"><span class="dvima">Long-horizon task generation and learning</span></h2>
                        <img src="assets/images/long-horizon.png" class="interpolation-image" alt=""
                            style="display: block; margin-left: auto; margin-right: auto; max-width: 80%;" />
                        <br>
                        <span style="font-size: 125%">RoboGen is able to propose high-level tasks, generate corresponding environments, decompose the high-level goal into low-level subtasks, and then learn the sub-skills sequentially.
                        </span>
                    </div>
                </div>
            </div>
        </div>
    </section> -->

    
    

  <section class="section">
    <div class="container is-max-widescreen">
  
  
  <div class="rows is-centered ">
    <div class="row is-full-width">
        <h2 class="title is-3"><span class="dvima">Real Lounge/Kitchen/Offices </span></h2>
    </div>
</div>
<br>
<p style="font-size: 125%">
We test ArticuBot in loungs/kitchen/offices on 7 unseen real-world articulated objects (a single policy) with a X-Arm on a mobile base. We use 2 Azure Kinects as the cameras. 
We test with the original X-Arm gripper, and also the UMI gripper. Videos are 5x speed.
</p>
<br>
<br>

  <div class="columns is-centered is-multiline">


      <div class="column is-one-third" style="padding-left: 2px; padding-right: 2px;">
        <div class="content" style="display: flex; flex-direction: column; align-items: center;">
          <video autoplay controls muted loop playsinline style="max-width: 80%;">
            <source src="./assets/nsh_a_drawer_trial_2.mp4"
                    type="video/mp4">
          </video>
          <p style="text-align:center; width: 80%;">Drawer</p>
        </div>
      </div>

      <div class="column is-one-third" style="padding-left: 2px; padding-right: 2px;">
        <div class="content" style="display: flex; flex-direction: column; align-items: center;">
          <video autoplay controls muted loop playsinline style="max-width: 80%;">
            <source src="./assets/nsh_a_fridge.mp4"
                    type="video/mp4">
          </video>
          <p style="text-align:center; width: 80%;">Fridge</p>
        </div>
      </div>


    <div class="column is-one-third" style="padding-left: 2px; padding-right: 2px;">
      <div class="content" style="display: flex; flex-direction: column; align-items: center;">
        <video autoplay controls muted loop playsinline style="max-width: 80%;">
          <source src="./assets/nsh_a_cabinet_trial_3.mp4"
                  type="video/mp4">
        </video>
        <p style="text-align:center; width: 80%;">cabinet</p>
      </div>
    </div>  

    <div class="column is-half" style="padding-left: 2px; padding-right: 2px;">
      <div class="content" style="display: flex; flex-direction: column; align-items: center;">
        <video autoplay controls muted loop playsinline style="max-width: 80%;">
          <source src="./assets/nsh4_cabinet_trial_3.mp4"
                  type="video/mp4">
        </video>
        <p style="text-align:center; width: 80%;">Cabinet wtih thin handle</p>
      </div>
    </div>  

    <div class="column is-half" style="padding-left: 2px; padding-right: 2px;">
      <div class="content" style="display: flex; flex-direction: column; align-items: center;">
        <video autoplay controls muted loop playsinline style="max-width: 80%;">
          <source src="./assets/robolounge_drawer_cut.mp4"
                  type="video/mp4">
        </video>
        <p style="text-align:center; width: 80%;">Drawer 2</p>
      </div>
    </div>
    
    <div class="column is-half" style="padding-left: 2px; padding-right: 2px;">
      <div class="content" style="display: flex; flex-direction: column; align-items: center;">
        <video autoplay controls muted loop playsinline style="max-width: 80%;">
          <source src="./assets/wooden_drawer_trial_1.mp4"
                  type="video/mp4">
        </video>
        <p style="text-align:center; width: 80%;">Drawer 3</p>
      </div>
    </div>
    

    <div class="column is-half" style="padding-left: 2px; padding-right: 2px;">
      <div class="content" style="display: flex; flex-direction: column; align-items: center;">
        <video autoplay controls muted loop playsinline style="max-width: 80%;">
          <source src="./assets/nsh4_dishwasher_trial_1.mp4"
                  type="video/mp4">
        </video>
        <p style="text-align:center; width: 80%;">Dishwasher (early stop due to excessive force)</p>
      </div>
    </div>
    
    
  </div>
</section>



  <section class="section">
    <div class="container is-max-widescreen">
  
  
      <div class="rows is-centered ">
        <div class="row is-full-width">
            <h2 class="title is-3"><span class="dvima">Real-World Lab A Test objects </span></h2>
        </div>
    </div>
    <br>
    <p style="font-size: 125%">
    We also test ArticuBot (the same policy) on 9 unseen real-world articulated objects with a table-top Franka Arm, and two Azure Kinects cameras in Lab A.
    Videos are 5x speed.
    </p>
    <br>
    <br>
  
      <div class="columns is-centered is-multiline">
        <div class="column is-one-third" style="padding-left: 2px; padding-right: 2px;">
          <div class="content" style="display: flex; flex-direction: column; align-items: center;">
            <video autoplay controls muted loop playsinline style="max-width: 100%;">
              <source src="./assets/3d_layer_drawer_trial_5.mp4"
                      type="video/mp4">
            </video>
            <p style="text-align:center; width: 100%;">3-layer cabinet</p>
          </div>
        </div>

        <div class="column is-one-third" style="padding-left: 2px; padding-right: 2px;">
          <div class="content" style="display: flex; flex-direction: column; align-items: center;">
            <video autoplay controls muted loop playsinline style="max-width: 100%;">
              <source src="./assets/knob_cabinet_trial_2.mp4"
                      type="video/mp4">
            </video>
            <p style="text-align:center; width: 100%;">knob cabinet</p>
          </div>
        </div>  

        <div class="column is-one-third" style="padding-left: 2px; padding-right: 2px;">
          <div class="content" style="display: flex; flex-direction: column; align-items: center;">
            <video autoplay controls muted loop playsinline style="max-width: 100%;">
              <source src="./assets/drawer_trial_2.mp4"
                      type="video/mp4">
            </video>
            <p style="text-align:center; width: 100%;">2-layer drawer</p>
          </div>
        </div>  



        <div class="column is-one-third" style="padding-left: 2px; padding-right: 2px;">
          <div class="content" style="display: flex; flex-direction: column; align-items: center;">
            <video autoplay controls muted loop playsinline style="max-width: 100%;">
              <source src="./assets/microwave_trial_5.mp4"
                      type="video/mp4">
            </video>
            <p style="text-align:center; width: 100%;">red microwave</p>
          </div>
        </div>  

        <div class="column is-one-third" style="padding-left: 2px; padding-right: 2px;">
          <div class="content" style="display: flex; flex-direction: column; align-items: center;">
            <video autoplay controls muted loop playsinline style="max-width: 100%;">
              <source src="./assets/white_cabinet_trial_1.mp4"
                      type="video/mp4">
            </video>
            <p style="text-align:center; width: 100%;">white cabinet</p>
          </div>
        </div>  

        <div class="column is-one-third" style="padding-left: 2px; padding-right: 2px;">
          <div class="content" style="display: flex; flex-direction: column; align-items: center;">
            <video autoplay controls muted loop playsinline style="max-width: 100%;">
              <source src="./assets/new_microwave_trial_3.mp4"
                      type="video/mp4">
            </video>
            <p style="text-align:center; width: 100%;">black microwave</p>
          </div>
        </div>  

        <div class="column is-one-third" style="padding-left: 2px; padding-right: 2px;">
          <div class="content" style="display: flex; flex-direction: column; align-items: center;">
            <video autoplay controls muted loop playsinline style="max-width: 100%;">
              <source src="./assets/toy_fridge_trial_1.mp4"
                      type="video/mp4">
            </video>
            <p style="text-align:center; width: 100%;">toy fridge</p>
          </div>
        </div>  

        <div class="column is-one-third" style="padding-left: 2px; padding-right: 2px;">
          <div class="content" style="display: flex; flex-direction: column; align-items: center;">
            <video autoplay controls muted loop playsinline style="max-width: 100%;">
              <source src="./assets/toy_oven_trial_1.mp4"
                      type="video/mp4">
            </video>
            <p style="text-align:center; width: 100%;">toy oven</p>
          </div>
        </div>  



        <div class="column is-one-third" style="padding-left: 2px; padding-right: 2px;">
          <div class="content" style="display: flex; flex-direction: column; align-items: center;">
            <video autoplay controls muted loop playsinline style="max-width: 100%;">
              <source src="./assets/knob_drawer_trial_2.mp4"
                      type="video/mp4">
            </video>
            <p style="text-align:center; width: 100%;">knob drawer</p>
          </div>
        </div>  
        
      </div>
    </section>


    <section class="section">
      <div class="container is-max-widescreen">
    
    
        <div class="rows is-centered ">
          <div class="row is-full-width">
              <h2 class="title is-3"><span class="dvima">Real World Lab B Test objects</span></h2>
          </div>
      </div>
      <br>
      <p style="font-size: 125%">
      We also test ArticuBot (the same policy as used in above experiments) on 4 unseen real-world articulated objects with a table-top Franka Arm, and two RealSense D435i cameras in Lab B.
      Videos are 5x speed.
      </p>
      <br>
      <br>
    
        <div class="columns is-centered is-multiline">
          <div class="column is-one-third" style="padding-left: 2px; padding-right: 2px;">
            <div class="content" style="display: flex; flex-direction: column; align-items: center;">
              <video autoplay controls muted loop playsinline style="max-width: 100%;">
                <source src="./assets/demo-green_cabinet-formal4.mp4"
                        type="video/mp4">
              </video>
              <p style="text-align:center; width: 100%;">Green cabinet</p>
            </div>
          </div>
  
          <div class="column is-one-third" style="padding-left: 2px; padding-right: 2px;">
            <div class="content" style="display: flex; flex-direction: column; align-items: center;">
              <video autoplay controls muted loop playsinline style="max-width: 100%;">
                <source src="./assets/demo-green_cabinet-formal5.mp4"
                        type="video/mp4">
              </video>
              <p style="text-align:center; width: 100%;">Green cabinet (flipped)</p>
            </div>
          </div>  
  
          <div class="column is-one-third" style="padding-left: 2px; padding-right: 2px;">
            <div class="content" style="display: flex; flex-direction: column; align-items: center;">
              <video autoplay controls muted loop playsinline style="max-width: 100%;">
                <source src="./assets/demo-red_storage_box-formal2.mp4"
                        type="video/mp4">
              </video>
              <p style="text-align:center; width: 100%;">Brown storage box</p>
            </div>
          </div>  
  
  
  
          <div class="column is-one-third" style="padding-left: 2px; padding-right: 2px;">
            <div class="content" style="display: flex; flex-direction: column; align-items: center;">
              <video autoplay controls muted loop playsinline style="max-width: 100%;">
                <source src="./assets/demo-red_storage_box-formal4.mp4"
                        type="video/mp4">
              </video>
              <p style="text-align:center; width: 100%;">Red strorage box</p>
            </div>
          </div>  
  
          <div class="column is-one-third" style="padding-left: 2px; padding-right: 2px;">
            <div class="content" style="display: flex; flex-direction: column; align-items: center;">
              <video autoplay controls muted loop playsinline style="max-width: 100%;">
                <source src="./assets/formal-demo-grey_drawer-formal1.mp4"
                        type="video/mp4">
              </video>
              <p style="text-align:center; width: 100%;">Drawer (bottom)</p>
            </div>
          </div>  
  
          <div class="column is-one-third" style="padding-left: 2px; padding-right: 2px;">
            <div class="content" style="display: flex; flex-direction: column; align-items: center;">
              <video autoplay controls muted loop playsinline style="max-width: 100%;">
                <source src="./assets/formal-demo-grey_drawer-formal2.mp4"
                        type="video/mp4">
              </video>
              <p style="text-align:center; width: 100%;">Drawer (top)</p>
            </div>
          </div>  
        </div>
      </section>


   
      <!-- interactive examples of long horizon tasks -->
      <section class="section">
        <div class="container is-max-widescreen">
            <div class="rows">
                <div class="rows is-centered">
                    <div class="row is-full-width">
                        <h2 class="title is-3"><span class="dvima">Visualizations of the learned policy outputs</span></h2>
                        <p style="font-size: 125%">Please click an image below to view the visualizations of the policy outputs.</p>
                    </div>
                </div>
            </div>
            <br>
            
            <!-- First row with 7 images -->
            <div class="columns is-centered">
              <div class="column is-full-width" style="display: flex; flex-wrap: wrap; justify-content: center;">
                  <img src="assets/chialiang-drawer.png" width="10%" height="auto" style="border-radius: 10px; margin: 5px; object-fit: cover; aspect-ratio: 1/1;" alt='Store an item' onclick="populateDemo(this, 1);">
                  <img src="assets/chialiang-green.png" width="10%" height="auto" style="border-radius: 10px; margin: 5px; object-fit: cover; aspect-ratio: 1/1;" alt='Heat soup' onclick="populateDemo(this, 1);">
                  <img src="assets/knob_cabinet.png" width="10%" height="auto" style="border-radius: 10px; margin: 5px; object-fit: cover; aspect-ratio: 1/1;" alt='Slide Window' onclick="populateDemo(this, 1);">
                  <img src="assets/mobile_base_fridge.png" width="10%" height="auto" style="border-radius: 10px; margin: 5px; object-fit: cover; aspect-ratio: 1/1;" alt='Gallop' onclick="populateDemo(this, 1);">
                  <img src="assets/nsh4_cabinet.png" width="10%" height="auto" style="border-radius: 10px; margin: 5px; object-fit: cover; aspect-ratio: 1/1;" alt='Rotate in place' onclick="populateDemo(this, 1);">
                  <img src="assets/robo_lounge_drawer.png" width="10%" height="auto" style="border-radius: 10px; margin: 5px; object-fit: cover; aspect-ratio: 1/1;" alt='Retrieve from safe' onclick="populateDemo(this, 1);">
                  <img src="assets/white_cabinet.png" width="10%" height="auto" style="border-radius: 10px; margin: 5px; object-fit: cover; aspect-ratio: 1/1;" alt='Unload Cart' onclick="populateDemo(this, 1);">
                  <img src="assets/oven.png" width="10%" height="auto" style="border-radius: 10px; margin: 5px; object-fit: cover; aspect-ratio: 1/1;" alt='Unload Cart' onclick="populateDemo(this, 1);">
              </div>
          </div>
          
            <!-- Video Player -->
            <div class="row border rounded" style="padding-top:2px; padding-bottom:12px; margin-top: 20px;">
                <div class="col-md-6">
                    <video id="demo-video-1" style="border-radius: 5px; width: 100%;" autoplay loop muted webkit-playsinline playsinline onclick="setAttribute('controls', 'true');">
                        <source id="expandedImg-1" src="assets/select.mp4" type="video/mp4">
                    </video>
                </div>
            </div>
            
            <!-- Text description -->
            <!-- <div class="col-md-6">
                <div id="imgtext-1" style="font-size: 1.5em">Select an image above to show the RoboGen results:</div>
                <div>
                    <pre class="p-1 scrollable"><code class="language-python" id="answer-1">RoboGen response shown within code block.</code></pre>
                </div>
            </div> -->
        </div>
    </section>
    
    <script>
    function populateDemo(img, demoId) {
        const videoSource = document.getElementById("expandedImg-" + demoId);
        const videoElement = document.getElementById("demo-video-" + demoId);
        const textElement = document.getElementById("imgtext-" + demoId);
    
        // Extract the video path based on the image source
        const videoPath = img.src.replace('.png', '.mp4').replace('assets/', 'assets/');
        videoSource.src = videoPath;
        videoElement.load(); // Reload video with new source
    
        // Update the text description
        textElement.innerHTML = img.alt;
    }
    </script>
    
          

        <section class="section">
          <div class="container is-max-widescreen">
              <div class="rows">
                  <div class="rows is-centered">
                      <div class="row is-full-width">
                          <h2 class="title is-3"><span class="dvima">Comparison to prior methods in the real world</span></h2>
                          <p style="font-size: 125%">
                          We compare to FlowBot3D and AO-Grasp on 9 objects in lab A.
                          As AO-Grasp only performs grasping, we compare against it in terms of grasping success rate.
                          As FlowBot3D originally uses a suction gripper for grasping, when comparing to FlowBot3D, we manually move the parallel jaw gripper to first grasp the 
                          handle of the object, then apply FlowBot3D to open it. We compare against it in terms of normalized opening performance.
                          We also compare to OpenVLA, which we find to fail to grasp or open any of the test objects. 
                          </p>
                          <br>
                          <br>

                          <img src="assets/real-world-results-2-1.png" alt="Example Image" style="max-width: 100%;">
    <p style="text-align:center; width: 100%;">Comparison to prior articulated object manipulation methods</p>
                          <br>
  
                          </p>
                          </div>
                  </div>
              </div>
          </div>
      </section>


      <section class="section">
        <div class="container is-max-widescreen">
            <div class="rows">
                <div class="rows is-centered">
                    <div class="row is-full-width">
                        <h2 class="title is-3"><span class="dvima">Comparison to non-hierarchical policy</span></h2>
                        <p style="font-size: 125%">
                        We compare ArticuBot, which uses a hierarchical policy, to a non-hierarchical policy, that learns to output 
                        eef end-effector delta transformations without conditioned on a learned predicted eef goal. 
                        We compare in terms of the normalized opening performance, when trained with different number of objects in simulation. 
                        As shown, using a hierarchical policy significantly outperforms the non-hierarchical policy.
                        Increasing the number of training objects do not bring much improvement for the non-hierarchical policy. 
                        </p>
                        <br>
                        <br>

                        <div style="display: flex; justify-content: center;">
                          <img src="assets/line_plot_hierarchical.png" alt="Example Image" style="max-width: 60%;">
                      </div>
  
                      <!-- Centered Caption -->
                      <p style="text-align:center; width: 100%;">Comparison of hierarchical and non-hierarchical policy.</p>
                      <br>

                        </p>
                        </div>
                </div>
            </div>
        </div>
    </section>


    <section class="section">
      <div class="container is-max-widescreen">
          <div class="rows">
              <div class="rows is-centered">
                  <div class="row is-full-width">
                      <h2 class="title is-3"><span class="dvima">Comparison of different high-level policy architecture</span></h2>
                      <p style="font-size: 125%">
                      We compare the weighted displacement model, which is the high-level policy used by ArticuBot, to 
                      several other methods for predicting the goal eef points: DP3 (wtih the default UNet diffusion),
                      DP3 (using a transformer for diffusion), and 3D Diffuser Actor (3DDA). 
                      These baselines directly diffuse the goal eef points, instead of predicting the displacement from the scene points to the goal eef points.
                      The proposed weighted displacement model outperforms these baselines especially when tested with unseen camera randomizations, 
                      which is crucial for sim2real transfer.
                      </p>
                      <br>
                      <br>

                      <div style="display: flex; justify-content: center;">
                        <img src="assets/camera_all_together_3.png" alt="Example Image" style="max-width: 100%;">
                    </div>

                    <!-- Centered Caption -->
                    <p style="text-align:center; width: 100%;">Comparison of different high-level policies. Leftmost: Train and test without camera randomizations. Right: Train with camera randomizations, and test with no camera randomization, with camera randomizations from training distribution, and with camera randomizations from an unseen test distribution.</p>
                    <br>

                      </p>
                      </div>
              </div>
          </div>
      </div>
  </section>

   
  <section class="section" id="acknowledgement">
    <div class="container is-max-widescreen content">
        <h2 class="title">Acknowledgement</h2>
        This material is based upon work supported by the Toyota Research Institute,  National Science Foundation under NSF CAREER Grant No. IIS-2046491, and NIST under Grant No. 70NANB24H314. Any opinions, findings, and
 conclusions or recommendations expressed in this material are
 those of the author(s) and do not necessarily reflect the views
 of Toyota Research Institute, National Science Foundation, or NIST.
    </div>
</section>


<section class="section" id="BibTeX">
    <div class="container is-max-widescreen content">
        <h2 class="title">BibTeX</h2>
  <pre><code>@inproceedings{Wang2025articubot,
      title={ArticuBot: Learning Universal Articulated Object Manipulation Policy via Large Scale Simulation},
      author={Wang, Yufei and Wang, Ziyu and Nakura, Mino and Bhowal, Pratik and Kuo, Chia-Liang and Chen, Yi-Ting and Erickson, Zackory and Held, David},
      booktitle={Robotics: Science and Systems (RSS)},
      year={2025}}   
</code></pre>
    </div>
</section>

    <footer class="footer">
        <div class="container">
            <div class="columns is-centered">
                <div class="column">
                    <div class="content has-text-centered">
                        <p>
                            Website template borrowed from <a
                                href="https://robogen-ai.github.io/">RoboGen</a> and <a
                                href="https://eureka-research.github.io/">Eureka</a>.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </footer>

</body>

<script>

  timeoutIds = [];

  function typeWriter(txt, i, q, num, text1, text2) {
      var imgText = document.getElementById(text1 + num);
      var answer = document.getElementById(text2 + num);
      if (imgText.innerHTML == q) {
          for (let k = 0; k < 5; k++) {
              if (i < txt.length) {
                  if (txt.charAt(i) == "\\") {
                      answer.innerHTML += "\n";
                      i += 1;
                  } else {
                      answer.innerHTML += txt.charAt(i);
                  }
                  i++;
              }
          }
          hljs.highlightAll();
          timeoutIds.push(setTimeout(typeWriter, 1, txt, i, q, num, text1, text2));
      }
  }

</script>

</html>